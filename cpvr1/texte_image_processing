strahlenmodell

brechungsindex: faktor für geschwindigkeit zu licht im vaakum (c/n m/s)
snell: bricht(Refraktion) zu lot (von leicht zu dichterem medium) --- beim eintritt: je mehr vom lot weg, desto mehr brichts zum lot
totalreflexion: unter flachem winkel reflektiert (dichteres medium)


**
Luminessenz:

Phonton ---> wird von Elektron absorbiert ---> Elektron kreist weiter entfernt um atomkern (gewinnt an energie)
Elektorn emissoniert Photon ---> photon fliegt weg --->  Elektron kreist wieder näher am Kern (verliert energie)

******
Lichtquellen

Wärestrahler
Natürlich: : Sonne, Blitz, brennendes Holz
Künstlich: Glühbirne, Halogen

Luminessenzstrahler
LED,Laser, Glühkäfer / Würmer, Fluoreszenz

*****
Sendefrequenz + Energie v. Photons = Proporzonal
Lichtgeschwindigkeit = 3*10^8 m/s

****
Wellenmodell
El-Feld und magnetFeld = senkrecht zueinander (Vaakum)
Sichtbarer Bereich 400-700nm, 1% der elmagnetischen Wellen
>Rot Infrarot
Rot (650-700)
Grün (540-550)
Blau (430-440)
>Blau = Ultraviolet

Brechungsindex von Welle abhängig (Prisma Weisses Licht -> regenbogen)

phasengeschwindigkeit lamda(distanz)/Peroidendauer(Zeit) -- phasengeschwindigkeit harmonische welle(bei überlagerungen)
Gruppengeschwindigkeit = Geschwindigkeit wie sich Wellenpaket fortbewegt

Warum Regenbogen: Wellen werden unterschiedlich gebrochen - Zweiter Regenbogen 1x mehr gebrochen

Polarisationsfilter
lässt nur eine Schwingungsausrichtung passieren
- Fotografie störende Spiegelung entfernen
- LCD Moditor für Pixelanzeige
- Sonnenbrille: Blau abdunkeln
- Tiefenblick (zwei Projektoren / überlagerung Bilder)

Auge:
Hornhaut ->  Kammerwasser -> Pupile -> Linse -> Netzhaut(Retina)


Pupille: Blende

Retina(Netzhaut)
Umcodierung d. Informationen

untere Schicht
- Ganglionzellen :  Kompression 130Mio Signale -> 1Mio verarbeitete
Mittlere Schicht
- Bipolar / Horizontalzellen
	--> für Kanten und Kontrastverstärkung
	--> Farbumcodierung
	--> Daten/Rauschreduzierung
	--> Umwandlung der L-Typ,M-Typ,S-Typ in GelbBlau, GrünRot, Helldunkel
obere Schicht
 Rezeptoren (Lichtempfindlich!)
 Kompression 130Mio Signale -> 1Mio verarbeitete

*****
Rezeptoren
- Enthalten Farbstoff Rhodopsin:
- Vitamin A für Spaltung in Bestandteile

-Stäbchen
 Hochempflindlich: breiter Wellenbereich
 Schwarzweiss sehen zuständig
 Tag: Abgeschalten - kommen bei Dämmerung zum einsatz

- Zäpfen
 Hochempfindlich: schmaler Wellenbereich
 Farbsehen zuständig

Verteilung 
 - ca 10 mehr Stäbchen 
 - fast alle Zapfen in Fovea - Farbsehen nur ca. 1 5CHF Stück - armlänge entfernt 


Farbsehen

	Hue: Farbton - Dominate Schwingung der Farbe
	Helligkeit 	 - Strahlungsdichte / Engerie des Lichtstrahls
	Sättigung 	 - (reiner Farbanteil- weissanteil) / (Reiner Farbanteil )

Tristimulustheorie
3 Zapfentypen
	L-Type: Gelb 40%
	M-Type: Grün 50%
	S-Type: Blau 10%

Additiv der Kurven: 55mn -> Grün

Umwandlung der L-Typ,M-Typ,S-Typ in GelbBlau, GrünRot, Helldunkel
-> Darum Farbblindheit /RotGrün / Gelbblau


Kontrastempfindlichkeit
- Helligkeit einer Fläche abhängig von Nachbarsflächen
- Datenreduktion --> Kantendedetion -> nur kanten ans hirn gesendet
- bei kreuzung 4 --> halb weiss halb schwarz
Frage: - Warum beim fokus kein solcher effekt?



RGB - Rot Grün Blau

 Additives Farbmischung	
 Raumdiagonale: graustufen
 Weiss: 1,1,1
 Cyian: 0,1,1 (türkis)
 Gelb: 1,1,0 
 Mangenta 1,0,1 (violett)
 gegenüberliegend: komplementärfarben

CMY-K
	RGB übereinander beim Druck nicht brauchbar.
	Subtraktive Farbmischung
	C = 1-R, absorbiert R, reflektiert G,B
	M = 1-G, absorberit G, reflektiert R,B
	Y = 1-B, absorbiert B, reflektiert R,G
	Undercover Removal: kleinster Farbanteil durch Schwarz(graustufe ersetzt)

HSV
	Hue (Farbton)
	Saturation(Sättigung)
	Leuchtdichtewert,Helligkeit(Value)

	Diamant
	Hue 
		Winkel, 0°C Rot 120° Grün 240° Blau
	Satt
		Abstand von Radius (0: Weiss;1 Farbton)
		Max(r,g,b) - min(r,g,b)/ max(r,g,b)
	Value 
		Tiefe ==> 0 Weiss, 1 Schwarz
		Max(r,g,b)
		Helligkeit
	H=0; S=0, => gerade --> alle graustufen v. Weiss bis Schwarz

	HSL, HSB --> H+S gleich, B/L gewichteter Mittelwert RGB (=Helligkeit)

PAL/ YUV (=Analog Fernsehen)

	Reduktion Bandbreite
	Kompatibel zu S/W
	Bewechte Bilder müssen nicht so detailiert sein (Fovea!)
	
	Y Helligkeitssignal Lumminanz
	U,V 2 Farbsignale Chrominanz

	Y = Mittlere Helligkeit (Graustufen: 0.3*R+0.6*G+0.1*B)
	U = Differenz Blauanteil zur Helligkeit
	V = Differenz Rotanteil zur Helligkeit

	Y Volle Auflösung übertragen (Kompatibel zu S/W Fernseher)
	U,Y Halbe Auflösung

YCbCr
	analog zu YUV für digtales Fernsehen
	Cb = Blue Yellow
	Cr = Green Red
	--> so werden Farben auch ans Gehirn weitergeleitet!

CNS Farbmodell 
	Beschreibung der Farbe in Worten Rot Grün 
	Farbon, Abstufungen zwischen Farbtönen, Grün-Blau
	Sättigung, Stark, gräulich
	Helligkeit: Dunkel, Hell


Optik
	Camera Obscura - sehr kleines Loch - lange Belichtungszeit 
	-> Heute Samellinse

	Brennpunkt F bei Sammellinse hinter Linse (Schnittpunkt gerade linie und strahl des Gegenstands)
	1/b + 1/g = 1/f
	Brennweite f: Linse <-> Brennpunkt
	Abbildungsmassstab = g/b = G/B 

	Blendenzahl k = f/D (Brennweite/Durchmesser d. öffnung)
	je grösser Zahl, desto kleiner Durchmesser -> desto weniger Licht kommt durch.
	Schärfentiefe -> je grösser Blendenzahl, desto Schärfer wirkt das Bild (wie camera obscura)


Abbildungsfehler (Aberration)
	Chromatische Abberation
	Unterschiedliche Brechungswinkel von Lichtstrahlen verschiedener Wellenlänge
	-->Gegenmassnahme: Farbenkorrigiertes Objektiv

	Spährische Abberation
 	- Spährische (mit Radius) Linsen sind günstiger -> ungenauer Brennpunkt
	-> Gegenmassnahme: Aspährische Linsen verwenden
 
	Verzeichnung Distorbation
	-> je kleiner Brennweite, desto grösser ist Distorbation
	-> Abbildungskreis beim Fischauge objektiv
	-> entstehen durch Blende (kann nicht vermieden werden)

	Vignettierung
		Lichtabnahme zum Rand.
		Lichtabnahme, wenn licht nicht mehr rechtwicklig auf den Sensor trifft.
		Mechanische Vignettierung: durch Fassungsteile des Objektives

Wie am besten Vignettierung verhindern??

Modulations Transfer Funktion

	Qualtitästmerkmal für Objektiv
		Muss S/W Linien Unterscheiden können -> Linien werden immer enger. (Linienpaare / mm)
	Auflösungsgrenze nimmt von Zentrum zu Rand um Faktor 2-3 ab.		
	

Objektivtypen

	Festbrennweitobjektive (keine Blenden / keine Fokuseinstellungen) - beste Objektive
	80-90 MTF Standard
	>120 	  Präzisionsobjektive

	Zoomobjektive variable Brennweite mit Fokus / Blendeneinstellung
	
	Telezentrische objektive 
		Orthogonale Projektion (Bildgrösse ist unabhängig von Gegenstandsweite)

Sensorgrösse & Auflösung
	Pixelgrösse ab 2.6nm nicht mehr entscheidend, da wir nicht mehr unterscheiden können (Fovea)
	

Spektrale Empfindlichkeit
	Kamerasensoren enthalten IR und UV Filter 

Sensorgrössen
	Quantumeffizienz: Wahrscheinlichkeit, das Photon absorbiert wird.
	Sättigungskapazität: Wieviele Photonen kann eine Zelle aufnhemen.
	Dynamic Range: verhältnis Sättigungskapazität zu minimal detektierbarer Photonenmenge
	Gain: Wie stark muss das Sensor Signal verstärkt werden.
	A/D Wandler: Anzahl Diskretionsschritte
	Noise: Durch die elektornik hinzugefügtes Rauschen.


Defekte Pixel:
	Tote Pixel: keine Sättigung 
	Warme Pixel: Sättigung randomized
	Heisse Pixel: volle Sättigung

Sensorrauschen:
	Photonenrauschen: Lichtstrom ist Poisson-Verteilt
	Dunkelstromrauschen: Erhitzung des Sensors (z.B. lange Belichtungszeiten)
	Ausleserauschen: Umwandlung von Photonen -> el Signale nicht gleichmässig
	Quantisierungsrauschen: A/W Wandlungsrauschen
	Fixed Pattern Rauschen: Verunreinigung auf Sensor
	Verstärkungsrauschen


Blooming

	Wenn Sättigungsgrenze eines Pixels erreicht, 
	Ladung schwappt auf benachbarte Pixel des Sensors usw
	Hardwaremässig: Anti-Blooming-Gates auf Sensoren.


Dunkelbild- und Weissbildkorrektor

Aufnahme Bild ohne Beleuchtung mit langer Beleuchtungszeit: Dunkelbild
Aufnahme Weisse Wand: Weissbild - für fixed Pattern Noise entfernung


Signal to Noise Ratio

Gross = Besser
SNR = 20*log(Signal/Noise)
SNR = Wurzel(NoElectrons) - Photonenrauschen 

PTSNR

	2 Signale: 1 ohne Rauschen / 2 mit Rauschen
	Wie Standardabweichung: wobei Wert Signal 1 ist mittelwert
	Log im Verhältnis zu max Pixelwert (z.b. 255)

CCD Bildsensor

	Je grösser Sensoren, desto Lichtempfindlicher, Mehr Dynamik - bei gleicher Sensorgrösse - Weniger Auflösung
	Ladungen werden von Zelle zu Zelle verschoben -> zeilenweise an den Verstärker weitergeleitet.
	-Auslesen eines einzelnen Pixels nicht möglich.
	-Verstärker notwendig.
	-Hoher Integrationsaufwand
	+ Grosse Lichtempflindlichkeit
	+ Wenig Rauschen

	Interlance CCD Bildsensor - Auslesen je eines Halbbildes
	-Bei Schnellen Bewegungen Sägezahneffekt
	Progressiv CCd SCAN -> jede Zeile eine Verschiebeeinheit -> braucht mehr speicherplatz


CMOS Sensoren
	-Jede Fotozelle hat einen Verstärken
	-Zugriff auf Speicherzelle wie beim RAM. 

	+ günstigere Herstellkosten
	+ weniger Stromverbrauch
	+ Schnell
	- Geringere Empfindlichkeit (Da kleinere Fotozellen) - kleinere Dynamik
	- Rolling Shutter (Zeilenweise Beleuchtung: Bei bewegten Objekten Verzerrung)
	- Rauschanfälliger ( geringe Dynamik -> grössere Verstärkung = mehr Rauschen)

Farbaufnahme Prinzipien

	parallel 3 s/w Chips -> abspielen wieder mit projektor und farbfilter
	seriell 1 s/w Chip -> fotografie: 3x hintereinander.
	Mosaik-Farb-Chip  -> Bayern Pattern
		Einfacher Algorithmus: 4 Pixel zu einem zusammenfassen (2x Grün / 1x Rot / 1x Blau)
		Raw-Format: Bild im Bayer Format
	Multilayer Chip
		Je nach Wellenlänge dringen Photonen unterschiedlich tief ins Silizium ein.
		+ höhere Auflösung
		+ keine Interpolationseffekte

Kameraschnittstellen
	Firewire
	USB
	Camera Link: braucht spezieller Framegrabber (A/D Wandler)
	CosXpress: neuer Standard seit 2010

**************
Statistische Bildauswertung

	Histogramm - Häufigkeitsverteilung der Grau / Farbwerte
	X-Achse: grauwerte
	Y-Achse: Häufigkeit

	Wahrscheinlichkeitsdichte funktion häufigkeiten / Summe aller Pixel
	Kumulatives Histogramm: für Automatische Kontrastanpassung (linearisierung)
	2D Histogramm: 1. Bild Kanal Intensität: x-Achse, 2.Bild Kanal Intensität: y Achse
		jede gefundene Wertkombination wird im historgramm in der positon [x,y] aufaddiert.
		Intensität wird im Histogramm mit Farbe dargestellt.

		Überblendung: werden bei x-max / y-max viele häufigkeiten gemessen -> überblendung / informationsverlust
		Korrelation: Histogramm diagonale: hohe korrelation.
		Heisse Pixel: 
		dynamikumfang: pixel nur auf einer achse verteilt: dieser kanal höherer dynamikumfang.

	Stat. Messgrösen
	Min    		: gmin
	Max    		: gmax
	dynamic		: gmax-gmin
	Kontrast	:(gmax-gmin)/(gmax+gmin)
	Mittelwert 	: average - mittlere helligkeit des bildes
	Mode		: häufigster Wert. (peak Histogramm)
	Standardabw : mass für kontrast
	Schiefe		: sum((g(x,y)-avg/s)^3)
	Wölbung		: sum((g(x,y)-avg/s)^4) Abweichung von Normalverteilung
	Entropy		: Informationsgehalt (Je höher die Entropie, desto gleichmäßiger und zufälliger ist etwas verteilt.)
				: GraustufenBild 1 Graustufe H=0
				: gleichmässig verteiltes Graubild: sum(log2(1/256)) entropie 8


Punktoperationen
	Invert: 255-g(x,y)
	Binarisierung: Threshold entscheidend / z.B. Otsu Algorithmus, Berechnung Threshold schwierig.
	Graustufen reduktion: Komprimierung, Abbildungsfunktion in Stufenform
	Lineare Helligkeitskorrektur: g(x,y) = c*g(x,y)+b <--- Konstante B wird angepasst.
	Gammakorrektur: Y = 2 Beinahme Schwarz(=kurve nach unten gekrümmt), Y = 1 Original, Y = 1/4 = sehr hell
					Aufhellung nicht gleichmässig(helle weniger stark als dunkle partikel)			
	
	Lineare Kontrastkorrektur: g(x,y) = c*g(x,y)+b, c bestimmt kontrast((gmax-gmin)/(gmax+gmin))
	Steilere Kurve: Mehr kontrast, flache kurve: weniger kontrast

	Automatische Kontrasterhöhung
		g(x,y) = (g(x,y)-gmin)*255/(gmax-gmin)
		Histogramm wird gestreckt
		Wenn gmin und Gmax = 0,255, dann keine Kontrasterhöhung möglich.
			-> nur Pixel mit gewisser Sättigung betrachten

	Kontrasterhöhung durch Histogrammausgleich
		Ziel: Histogramm gleichverteilt, Kumulatives Histogramm: Linear
		f(g) = H(g)* (K-1)/N :K grösstmöglicher Grauwert; N summer aller Pixel H(g) Kumulatives Historgramm
		Wenn wenig Farben -> kommt zu rauschen, da die Graustufen zu fest aufgeteilt werden.
		Kontraste als Farben darstellen ( Mensch kann nur ca. 60 Graustufen unterscheiden)
	

Bildarithmetik
	+,-,*,/ g(x,y)*k1+k2
	eignet sich gut, um Beleuchtungsvariationen aus Bild zu entfernen. (bevor binarisierung)
	Bei Division idr. k1 gross, Subtraktion: k2 gross
	Absolute Differenz:
	g1(x,y) - g2(x,y) -> verschobene Objekte detektieren --> was gleicht ist: schwarz 
	
Logische Operationen
	Wichtig: Weiss = 1, Schwarz = 0
	Invert: XOR Weiss
	

Lokale Operatoren
	lineare lokale Operatoren
	Faltung / Convolution
	Filter wird über einen bereich gelegt, und jedem pixel eine Gewichtung zugeteilt.
	Eigenschaften d. Faltung: 
		Kommutativ g*h = (h*g)*i
		Assosizativ: g*h*i = (g*h)*i	
		Distributiv: g*h+i*h = (g+i)*h (nur für lineare faltungen)
	Separierbarkeit von Filtern:
		Filter in x und y komponente zerlegen 
		von n^2 zu 2n komplexität verringern: siehe: https://de.wikipedia.org/wiki/Separierbarkeit


Tiefpassfilter
	Bild wird weicher
	Grauwertkanten werden verwischt
	Details und Rauschen entfernt.
	in homogenen Bereich: keine Wirkung	
	Rechteckfilter: 1/9*[1,1,1;1,1,1;1,1,1]

	Gaussfilter: 
		besserer Tiefpassfilter, 
		basiert auf Normalverteilung
		je nach sigma anderer Filter
		1/16* [1,2,1;2,4,2;1,2,1]
		
Hochpassfilter
	Kanten werden weiss (kanten bestehen aus sehr vielen kleine wellen)
	Rauschen verstärkt (bei jeder ableitung stärker)
	Homogene Bereiche: Schwarz.
	-> 1. und 2. ableitung
	[-1,0,1;-1,0,1;-1,0,1] in x Richtung
	[-1,-1,-1;0,0,0;1,1,1] in y Richtung
	Gradientenbetrag: Wurzel(filterX^2 + filterY^2)
	Gradientenrichtung atan(filterx,filtery)
	Achtung: negative Kanten verschwinden

	Sobel: Gauss + 1. Ableitung
	SobelX[-1,0,1;-2,0,2;-1,0,1]
	Negative Kanten verschwinden.

	Kantendedektion in Beide Richtungen: approx 2. ableitung
		Laplace [1,1,1;1,-8,1;1,1,1,1] --> wie felder in der netzhaut, welche für kontrastsehen zuständig sind.
		Sehr anfällig auf Rauschen
		Laplace + Gauss -> mexican hat.

	Punktspreizfunktion
	[0,0,0;
	 0,1,0; für's finden von faltungsmasken --> faltungsmaske ist im frequenzraum invers.
	 0,0,0]


Anwendung Bildschärfung.
	Unscharfmaskierung: Tiefpassfilter
	Ansonsten mit Laplace+Gaussian 2. Ableitung: Hochpassfilter


Morphologische Operatoren
	
	SE (Strukturelement) hat immer einen Hotspot (anker)
		Wenn nicht quadratisch: restliche elemente "dont care"
	Wahl des SE matchentscheidend	
	Dilatation (=anfetten)
		Rangordnung: Zielpixel = MAX aller Pixel in SE
		Logische Ordnung: Or operation aller Pixel im SE

	Erosion(=abnehmen)
		Rangordnung: Zielpixel = MIN aller Pixel in SE
		Logische Ordnung: And operation aller Pixel im SE

	Closing 
		Dilatation, danach Erosion
		Löchen geschlossen
		Concave Ränger ausgefüllt
	Opening
		Erosion, danach Dilatation
		kleine Strukturen verschwinden 
		Konkave Ränder abgetragen

	Edge Detection
	edge Intern	B - (B erosion S)
	edge extern B diletation S - B
	edge thick (B diletation S) - (B erosion S)

	Hit Or Miss Operator
		(B ero S) AND (S^c dil S^c) = startpunkt gesuchtes Element
		Dont Care evt. mit 0 ersetzen. 

	...Auf Graustufenbilder
		Als 3D Bilder darstellbar
		SE enthalten reele Zahlen
		Nur mit Rangordnungsoperationen realisierbar
		Pixelwerte des Zielpixels werden jetzt auch berücksichtigt.
		dilatation: max(G(x+i,y+j) +s(i,j))
		erosion: min(g(x+i,y+j) - s(i,j))

		Ist SE überall null -> dilatation -> maximumsfilter; erosion: minimumsfilter

	Medianfilter
		Besterweichzeichner
		Ist nicht anfällig gegen Rauschen
		Kanten bleiben erhalten
	
	Opening / Closing Graustufenbilder
		Closing: Helle Details bleiben - Dunkle verschwinden
			x,y Skala: füllt löcher auf
		Opening: Dunkle Details bleiben, Helle verschwinden
			x,y Skala: schneidet wipfel ab

	Edge detection: Wie binäre operation

		edge Intern	B - (B erosion S)
		edge extern B diletation S - B
		edge thick (B diletation S) - (B erosion S)
		edge thin min(edge intern, edge extern)


	Bot Hat / Top Hat 
		Bot hat = Closing - B
			kleine Details, welche dunkler als Umgebung sind -> weiss
		Top Hat = B - Opening
			kleine Details, welche heller als Umgebung sind -> weiss
			 

Globale Operationen
	Smoothie -> Rezept = Transformation
	Rezept -> Smoothie = Synthese
		
	Fourier Transformation
		Jedes Periodische Signal: endliche Summe von Sinus und Cos Signalen	
		SinusSchwingung: A*sin(w*x+y)
		w Kreisfrequenz 2pif = w
		T(dauer) = 2PI/w von hochpunkt zu hochpunkt
		sinusoid = cos(wx)+i*sin(w*x)
		
		Transformation
		1/2pi*Integral(g(x)*(-cos(w*x)-sin(w*x)) 
		g(m) =1/Wurzel(M)*Summe(0..M, g(u)*e^(i*2pi*m*u)/M
		M:länge des Signals
		pro Sin/Cos-Signal: 1 Iteraton über das ganze Signal 
		Erstes Sinusschwingung: DC (mittelwert der Signalwerte)
		von tief bis hohe frequenzen 
		
		Eingangssignale: Komplexe Zahlen (bei transformation: imaginärteil:0)
		Ausgangssignal:  Komplexe Zahlen

		Amplitude = Wurzel(g(m)real^2+g(m)imag^2)
		Phase = atan(gimag(m)/greal(m))	
		in 2D 4 verschachtelete Schlaufen
		FFT verbessert zu n log n
		Nyquistfrequenz: M/2

		2D Fouriertransformation
		Bilder Spiegeln: sonst sehr hohe frequenzen
		M*N Signal 
		Sinusfrequenz 2D = 2PI*(U*m+V*n)
		Amplitude Wurzel(U^2+V^2)
		Phase tan^-1(U/V)
		Ausgabe: M*N Array aus komplexen Zahlen
		Amplitude: Auskunkft über Signalstärke
			hohe und tiefe frequenzen können auch im frequenzraum entfernt werden.
			-> inbs. strukturelle störungen gut erkenntbar.
		Phase: Ortsinformationen
		Faltungssatz: g*h = IFT(FT(g)*FT(h)) --> komponentenmultiplikation -> Inverse (Entfaltung: Division möglich)
			Wenn Pointspreadfunction bekannt --> Verfälschtes Bild wiederherstellbar
			sehr, sehr, sehr rauschanfällig
			suchen nach PSF (= blind deconvolution)
		grosse Bilder: Faltung mit Fourier u.u. Schneller

	Wavlet:
		nicht bekannt wo sind die entsprechende Schwingungen bei der Fouriertransformation befinden.
		(=Windowed Fourier Transformation)
		Nachteil: unempflindlich gegen kleine Frequenzen, die nur sporadisch auftreten
		
		Verbesserung: Wavlet-Tranformation: Analyse der Frequenzen in mehreren Auflösungen
		Anwendung: Bildkompression; dynamische Auflösungen (wg. geringer Datenmenge)
		Integral des Wavlets = 0!
		Beispiele: Wavelets: Mexican Hut, Haar Wavlet
		zuerst tiefe, dann immer höhere Frequenzen bestimmen
		1 Basis Wavlet: Kinder Wavlet: skaliert, verschoben CWT(a,b) a = skalierungsfaktor; b = verschiebung im ort.
		Beginn mit sehr tiefer gestrekter Frequenz: multiplikation mit überdektem funktionsabschnitt -> wavlet koeffizient (= grosse fläche = grosse übereinstimmung)
		Haartransformation:
			Tiefpass: [0.5,0.5]
			Hochpass [0.5,-0.5]
			synthese links [1,1]
			synthese rechts [1,-1]
		2D Haartransformation: immer 4 filter -> 1 tiefpass, 1 hochpass, synthesefilter links, synthesefilter rechts
		Standard deconvolution: zuerst Zeilen, dann Spalten
		non Standard deconvoltion: zeilen und spalten abwechslungsweise

	Hough Transformation

		Sehr umempfindlich gegen Rauschen / Lücken in Geraden, Kreisen, ect
		Ohne Parametereinschränkung: Sehr speicherintensiv
		r = x*cos(phi)+ y*sin(phi) für geraden
		Steigung:-( cos(phi) / sin(phi) )
		x-achse theta
		y-achse r
		Anzahl Element muss bekannt sein.
		Akkumulator-Raum
		Vor gebrauch: Maximum ermitteln (sonst wird eine gerade u.u. 2x detektiert)
		Non-Maximum Supression (z.B. filter 3x3 -> alles killen ausser maximum)

		Kreise
		(x-x0)^2+(y-y0)^2 = r^2
		x0,y0 = zentrum des kreises
		für jeden radius einen parallelraum


	Hauptkomponententransformation
		mehrdimensionale datenräume auf eine dimension reduziert
		Merkmalsvektor: alle Werte einer Position (aus n dimension)
		XPC = MEigenvektoren*M Merkmalsvektoren (matrix aus eigenvektoren * matrix aus merkmalsvektoren)
		kovarianz = 1/n*Sum(Xi-xmean)*(yi-ymean))
		Kovarmatrix: cxy = 
			[cov(x,x),cov(x,y)
			 cov(y,x),cov(y,y)]
		bei mehreren dimensionen: jede mit jeder dimension	
		aus kovarmatrix: eigenvektoren / eigenwerte berechnen
			sortierung nach grösstem eigenwert
		eig(x,y)^t *mekrmalsvektor^t = PCA
		merkmalsvektor wird transponiert und der mittelwert von jedem element subtrahiert.


		sehr anfällig gegen beleuchtungsveränderungen
		eigenvektor: A*v = lamda*v
		v= eigenvektor, lamda = eigenwert
		eigesetzt für statistische klassifikation
		mustererkennung - gesichtserkennung
		Interpretation: PCA Diagramm: 1. Achse Dimension mit grösster Varianz; 2. Achse 2. grösste Varianz
		Berechnung oriented bounding box: (1x sigma: 68% des objekts befinden sich darin) --> auf 3x sigma erweitern
			-> es braucht x,-x,y,-y vektor für die bestimmung der oriented bounding box
		
